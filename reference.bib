@article{lapointe_primary_2018,
	title = {Primary brain tumours in adults},
	volume = {392},
	issn = {0140-6736},
	url = {https://www.sciencedirect.com/science/article/pii/S0140673618309905},
	doi = {10.1016/S0140-6736(18)30990-5},
	abstract = {Primary {CNS} tumours refer to a heterogeneous group of tumours arising from cells within the {CNS}, and can be benign or malignant. Malignant primary brain tumours remain among the most difficult cancers to treat, with a 5 year overall survival no greater than 35\%. The most common malignant primary brain tumours in adults are gliomas. Recent advances in molecular biology have improved understanding of glioma pathogenesis, and several clinically significant genetic alterations have been described. A number of these ({IDH}, 1p/19q codeletion, H3 Lys27Met, and {RELA}-fusion) are now combined with histology in the revised 2016 {WHO} classification of {CNS} tumours. It is likely that understanding such molecular alterations will contribute to the diagnosis, grading, and treatment of brain tumours. This progress in genomics, along with significant advances in cancer and {CNS} immunology, has defined a new era in neuro-oncology and holds promise for diagntic and therapeutic improvement. The challenge at present is to translate these advances into effective treatments. Current efforts are focused on developing molecular targeted therapies, immunotherapies, gene therapies, and novel drug-delivery technologies. Results with single-agent therapies have been disappointing so far, and combination therapies seem to be required to achieve a broad and durable antitumour response. Biomarker-targeted clinical trials could improve efficiencies of therapeutic development.},
	pages = {432--446},
	number = {10145},
	journaltitle = {The Lancet},
	shortjournal = {The Lancet},
	author = {Lapointe, Sarah and Perry, Arie and Butowski, Nicholas A},
	urldate = {2024-06-02},
	date = {2018-08-04},
}

@article{nalepa_data_2019,
	title = {Data Augmentation for Brain-Tumor Segmentation: A Review},
	volume = {13},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2019.00083},
	doi = {10.3389/fncom.2019.00083},
	shorttitle = {Data Augmentation for Brain-Tumor Segmentation},
	abstract = {Data augmentation is a popular technique which helps improve generalization capabilities of deep neural networks, and can be perceived as implicit regularization. It plays a pivotal role in scenarios in which the amount of high-quality ground-truth data is limited, and acquiring new examples is costly and time-consuming. This is a very common problem in medical image analysis, especially tumor delineation. In this paper, we review the current advances in data-augmentation techniques applied to magnetic resonance images of brain tumors. To better understand the practical aspects of such algorithms, we investigate the papers submitted to the Multimodal Brain Tumor Segmentation Challenge ({BraTS} 2018 edition), as the {BraTS} dataset became a standard benchmark for validating existent and emerging brain-tumor detection and segmentation techniques. We verify which data augmentation approaches were exploited and what was their impact on the abilities of underlying supervised learners. Finally, we highlight the most promising research directions to follow in order to synthesize high-quality artificial brain-tumor examples which can boost the generalization abilities of deep models.},
	journaltitle = {Frontiers in Computational Neuroscience},
	shortjournal = {Front. Comput. Neurosci.},
	author = {Nalepa, Jakub and Marcinkiewicz, Michal and Kawulok, Michal},
	urldate = {2024-06-02},
	date = {2019-12-11},
	keywords = {Data augmentation, deep learning, Deep neural network, image segmentation, {MRI}},
}

@article{doi:10.1148/ryai.230095,
author = {Mahmutoglu, Mustafa Ahmed and Preetha, Chandrakanth Jayachandran and Meredig, Hagen and Tonn, Joerg-Christian and Weller, Michael and Wick, Wolfgang and Bendszus, Martin and Brugnara, Gianluca and Vollmuth, Philipp},
title = {Deep Learning–based Identification of Brain MRI Sequences Using a Model Trained on Large Multicentric Study Cohorts},
journal = {Radiology: Artificial Intelligence},
volume = {6},
number = {1},
pages = {e230095},
year = {2024},
doi = {10.1148/ryai.230095},
    note ={PMID: 38166331},

URL = { 
    
        https://doi.org/10.1148/ryai.230095
    
    

},
eprint = { 
    
        https://doi.org/10.1148/ryai.230095
    
    

}
,
    abstract = { Purpose To develop a fully automated device- and sequence-independent convolutional neural network (CNN) for reliable and high-throughput labeling of heterogeneous, unstructured MRI data. Materials and Methods Retrospective, multicentric brain MRI data (2179 patients with glioblastoma, 8544 examinations, 63 327 sequences) from 249 hospitals and 29 scanner types were used to develop a network based on ResNet-18 architecture to differentiate nine MRI sequence types, including T1-weighted, postcontrast T1-weighted, T2-weighted, fluid-attenuated inversion recovery, susceptibility-weighted, apparent diffusion coefficient, diffusion-weighted (low and high b value), and gradient-recalled echo T2*-weighted and dynamic susceptibility contrast-related images. The two-dimensional-midsection images from each sequence were allocated to training or validation (approximately 80\%) and testing (approximately 20\%) using a stratified split to ensure balanced groups across institutions, patients, and MRI sequence types. The prediction accuracy was quantified for each sequence type, and subgroup comparison of model performance was performed using χ2 tests. Results On the test set, the overall accuracy of the CNN (ResNet-18) ensemble model among all sequence types was 97.9\% (95\% CI: 97.6, 98.1), ranging from 84.2\% for susceptibility-weighted images (95\% CI: 81.8, 86.6) to 99.8\% for T2-weighted images (95\% CI: 99.7, 99.9). The ResNet-18 model achieved significantly better accuracy compared with ResNet-50 despite its simpler architecture (97.9\% vs 97.1\%; P ≤ .001). The accuracy of the ResNet-18 model was not affected by the presence versus absence of tumor on the two-dimensional-midsection images for any sequence type (P > .05). Conclusion The developed CNN (www.github.com/neuroAI-HD/HD-SEQ-ID) reliably differentiates nine types of MRI sequences within multicenter and large-scale population neuroimaging data and may enhance the speed, accuracy, and efficiency of clinical and research neuroradiologic workflows. Keywords: MR-Imaging, Neural Networks, CNS, Brain/Brain Stem, Computer Applications-General (Informatics), Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms Supplemental material is available for this article. © RSNA, 2023 }
}

@article{Islam_Barua_Rahman_Ahammed_Akter_Uddin_2023, title={Transfer learning architectures with fine-tuning for brain tumor classification using Magnetic Resonance Imaging}, volume={4}, DOI={10.1016/j.health.2023.100270}, journal={Healthcare Analytics}, author={Islam, Md. Monirul and Barua, Prema and Rahman, Moshiur and Ahammed, Tanvir and Akter, Laboni and Uddin, Jia}, year={2023}, month={Dec}, pages={100270}} 

@InProceedings{10.1007/978-3-030-32695-1_7,
author="Thomas, Armin W.
and M{\"u}ller, Klaus-Robert
and Samek, Wojciech",
editor="Zhou, Luping
and Sarikaya, Duygu
and Kia, Seyed Mostafa
and Speidel, Stefanie
and Malpani, Anand
and Hashimoto, Daniel
and Habes, Mohamad
and L{\"o}fstedt, Tommy
and Ritter, Kerstin
and Wang, Hongzhi",
title="Deep Transfer Learning for Whole-Brain FMRI Analyses",
booktitle="OR 2.0 Context-Aware Operating Theaters and Machine Learning in Clinical Neuroimaging",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="59--67",
abstract="The application of deep learning (DL) models to the decoding of cognitive states from whole-brain functional Magnetic Resonance Imaging (fMRI) data is often hindered by the small sample size and high dimensionality of these datasets. Especially, in clinical settings, where patient data are scarce. In this work, we demonstrate that transfer learning represents a solution to this problem. Particularly, we show that a DL model, which has been previously trained on a large openly available fMRI dataset of the Human Connectome Project, outperforms a model variant with the same architecture, but which is trained from scratch, when both are applied to the data of a new, unrelated fMRI task. The pre-trained DL model variant is able to correctly decode 67.51{\%} of the cognitive states from a test dataset with 100 individuals, when fine-tuned on a dataset of the size of only three subjects.",
isbn="978-3-030-32695-1"
}

@INPROCEEDINGS{10125766,
  author={Mitta, Anirudh B. and Hegde, Ajay H. and P., Asha Rani K. and S., Gowrishankar},
  booktitle={2023 7th International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Brain Tumor Detection: An Application based on Transfer Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1424-1430},
  keywords={Deep learning;Training;Magnetic resonance imaging;Transfer learning;Brain modeling;Data models;Classification algorithms;Brain Tumor;Machine Learning;Transfer Learning;Models;Accuracy;Precision;Convolution Neural Network;Magnetic Resonance Imaging},
  doi={10.1109/ICOEI56765.2023.10125766}}


@article{Paul2017Deep,title={Deep learning for brain tumor classification},author={Justin S. Paul and A. Plassard and B. Landman and D. Fabbri},year={2017},volume={10137},doi={10.1117/12.2254195}}

@article{Fahimi2020Generative,title={Generative Adversarial Networks-Based Data Augmentation for Brain–Computer Interface},author={Fatemeh Fahimi and S. Došen and K. Ang and N. Mrachacz‐Kersting and Cuntai Guan},journal={IEEE Transactions on Neural Networks and Learning Systems},year={2020},volume={32},pages={4039-4051},doi={10.1109/tnnls.2020.3016666}}

@INPROCEEDINGS{10183465,
  author={Krishna, Divi Leela and Dedeepya Padmanabhuni, Naga Venkata and JayaLakshmi, G},
  booktitle={2023 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)}, 
  title={Data Augmentation Based Brain Tumor Detection Using CNN and Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={317-321},
  keywords={Deep learning;Machine learning algorithms;Magnetic resonance imaging;Logic gates;Brain modeling;Data augmentation;Data models;Brain Tumor;ResNet-50;VGG-16;DenseNet-121;Magnetic Resonance Imaging;Convolutional Neural Networks;Data Augmentation},
  doi={10.1109/CISES58720.2023.10183465}}
  
  @article{Asif2022Improving,title={Improving Effectiveness of Different Deep Transfer Learning-Based Models for Detecting Brain Tumors From MR Images},author={S. Asif and Wenhui Yi and Q. Ain and Jinhai Hou and Tao Yi and Jinhai Si},journal={IEEE Access},year={2022},volume={10},pages={34716-34730},doi={10.1109/ACCESS.2022.3153306}}


@article{lenchik_automated_2019,
	title = {Automated Segmentation of Tissues Using {CT} and {MRI}: A Systematic Review},
	volume = {26},
	issn = {1076-6332, 1878-4046},
	url = {https://www.academicradiology.org/article/S1076-6332(19)30353-8/abstract},
	doi = {10.1016/j.acra.2019.07.006},
	shorttitle = {Automated Segmentation of Tissues Using {CT} and {MRI}},
	pages = {1695--1706},
	number = {12},
	journaltitle = {Academic Radiology},
	shortjournal = {Academic Radiology},
	author = {Lenchik, Leon and Heacock, Laura and Weaver, Ashley A. and Boutin, Robert D. and Cook, Tessa S. and Itri, Jason and Filippi, Christopher G. and Gullapalli, Rao P. and Lee, James and Zagurovskaya, Marianna and Retson, Tara and Godwin, Kendra and Nicholson, Joey and Narayana, Ponnada A.},
	urldate = {2024-06-08},
	date = {2019-12-01},
	pmid = {31405724},
	note = {Publisher: Elsevier},
	keywords = {background parenchymal enhancement, {BPE}, {CNN}, convolutional neural network, {CT}, Dice Similarity Coefficient, {DSC}, {FGT}, fibroglandular tissue, machine learning, Machine learning, Medical Image Computing and Computer Assisted Intervention, {MICCAI}, {ML}, {MRI}, Quantitative imaging, Segmentation},
}

  
@article{iorgulescu_misclassification_2019,
	title = {The Misclassification of Diffuse Gliomas: Rates and Outcomes},
	volume = {25},
	issn = {1078-0432},
	url = {https://doi.org/10.1158/1078-0432.CCR-18-3101},
	doi = {10.1158/1078-0432.CCR-18-3101},
	shorttitle = {The Misclassification of Diffuse Gliomas},
	abstract = {The integrated histopathologic and molecular diagnoses of the 2016 {WHO} classification of central nervous system tumors have revolutionized patient care by improving diagnostic accuracy and reproducibility; however, the frequency and consequences of misclassification of histologically diagnosed diffuse gliomas are unknown.Patients with newly diagnosed {ICD}-O-3 (International Classification of Diseases) histologically encoded diffuse gliomas from 2010–2015 were identified from the National Cancer Database, the misclassification rates and overall survival ({OS}) of which were assessed by {WHO} grade and 1p/19q status. In addition, misclassification rates by isocitrate dehydrogenase ({IDH}), {ATRX}, and p53 statuses were examined in an analogous multi-institutional cohort of registry-encoded diffuse gliomas.Of 74,718 patients with diffuse glioma, only 74.4\% and 78.8\% of molecularly characterized {WHO} grade {II} and {III} oligodendrogliomas were in fact 1p/19q-codeleted. In addition, 28.9\% and 36.8\% of histologically encoded grade {II} and {III} “oligoastrocytomas”, and 6.3\% and 8.8\% of grade {II} and {III} astrocytomas had 1p/19q-codeletion, thus molecularly representing oligodendrogliomas if also {IDH} mutant. {OS} significantly depended on accurate {WHO} grading and 1p/19q status.On the basis of 1p/19q, {IDH}, {ATRX}, and p53, the misclassification rates of histologically encoded oligodendrogliomas, astrocytomas, and glioblastomas are approximately 21\%–35\%, 6\%–9\%, and 9\%, respectively; with significant clinical implications. Our findings suggest that when compared with historical histology-only classified data, in national registry, as well as, institutional databases, there is the potential for false-positive results in contemporary trials of molecularly classified diffuse gliomas, which could contribute to a seemingly positive phase {II} trial (based on historical comparison) failing at the phase {III} stage. Critically, findings from diffuse glioma clinical trials and historical cohorts using prior histology-only {WHO} schemes must be cautiously reinterpreted.},
	pages = {2656--2663},
	number = {8},
	journaltitle = {Clinical Cancer Research},
	shortjournal = {Clinical Cancer Research},
	author = {Iorgulescu, J. Bryan and Torre, Matthew and Harary, Maya and Smith, Timothy R. and Aizer, Ayal A. and Reardon, David A. and Barnholtz-Sloan, Jill S. and Perry, Arie},
	urldate = {2024-06-08},
	date = {2019-04-15},
}

  
@article{rolnick_tackling_2022,
	title = {Tackling Climate Change with Machine Learning},
	volume = {55},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3485128},
	doi = {10.1145/3485128},
	abstract = {Climate change is one of the greatest challenges facing humanity, and we, as machine learning ({ML}) experts, may wonder how we can help. Here we describe how {ML} can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by {ML}, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the {ML} community to join the global effort against climate change.},
	pages = {42:1--42:96},
	number = {2},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Rolnick, David and Donti, Priya L. and Kaack, Lynn H. and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and Luccioni, Alexandra Sasha and Maharaj, Tegan and Sherwin, Evan D. and Mukkavilli, S. Karthik and Kording, Konrad P. and Gomes, Carla P. and Ng, Andrew Y. and Hassabis, Demis and Platt, John C. and Creutzig, Felix and Chayes, Jennifer and Bengio, Yoshua},
	urldate = {2024-06-08},
	date = {2022-02-07},
	keywords = {adaptation, artificial intelligence, Climate change, machine learning, mitigation},
}

  
@article{doupe_machine_2019,
	title = {Machine Learning for Health Services Researchers},
	volume = {22},
	issn = {1098-3015, 1524-4733},
	url = {https://www.valueinhealthjournal.com/article/S1098-3015(19)30146-9/fulltext?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS1098301519301469%3Fshowall%3Dtrue},
	doi = {10.1016/j.jval.2019.02.012},
	pages = {808--815},
	number = {7},
	journaltitle = {Value in Health},
	shortjournal = {Value in Health},
	author = {Doupe, Patrick and Faghmous, James and Basu, Sanjay},
	urldate = {2024-06-08},
	date = {2019-07-01},
	pmid = {31277828},
	note = {Publisher: Elsevier},
	keywords = {claims data, deep learning, elastic net, gradient boosting machine, gradient forest, health services research, machine learning, neural networks, random forest},
}

  
@article{nazar_systematic_2021,
	title = {A Systematic Review of Human–Computer Interaction and Explainable Artificial Intelligence in Healthcare With Artificial Intelligence Techniques},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9614151},
	doi = {10.1109/ACCESS.2021.3127881},
	abstract = {Artificial intelligence ({AI}) is one of the emerging technologies. In recent decades, artificial intelligence ({AI}) has gained widespread acceptance in a variety of fields, including virtual support, healthcare, and security. Human-Computer Interaction ({HCI}) is a field that has been combining {AI} and human-computer engagement over the past several years in order to create an interactive intelligent system for user interaction. {AI}, in conjunction with {HCI}, is being used in a variety of fields by employing various algorithms and employing {HCI} to provide transparency to the user, allowing them to trust the machine. The comprehensive examination of both the areas of {AI} and {HCI}, as well as their subfields, has been explored in this work. The main goal of this article was to discover a point of intersection between the two fields. The understanding of Explainable Artificial Intelligence ({XAI}), which is a linking point of {HCI} and {XAI}, was gained through a literature review conducted in this research. The literature survey encompassed themes identified in the literature (such as {XAI} and its areas, major {XAI} aims, and {XAI} problems and challenges). The study’s other major focus was on the use of {AI}, {HCI}, and {XAI} in healthcare. The poll also addressed the shortcomings in {XAI} in healthcare, as well as the field’s future potential. As a result, the literature indicates that {XAI} in healthcare is still a novel subject that has to be explored more in the future.},
	pages = {153316--153348},
	journaltitle = {{IEEE} Access},
	author = {Nazar, Mobeen and Alam, Muhammad Mansoor and Yafi, Eiad and Su’ud, Mazliham Mohd},
	urldate = {2024-06-08},
	date = {2021},
	note = {Conference Name: {IEEE} Access},
	keywords = {Artificial intelligence, Data models, deep learning, explainable artificial intelligence, healthcare, Human computer interaction, human-centered design, human-computer interaction, machine learning, Medical services, Security, Systematics, usability, Usability, user-centered design},
}


  
@inproceedings{imtiaz_brain_2023,
	title = {Brain Tumor Segmentation from {MR} Images using Customized U-net for a Smaller Dataset},
	url = {https://ieeexplore.ieee.org/document/10389092},
	doi = {10.1109/BioCAS58349.2023.10389092},
	abstract = {In medical image analysis, deep learning has emerged as a powerful tool for solving complex tasks such as segmentation. This research presents an original approach using a customized U-net model for automatic brain tumor segmentation in Magnetic resonance imaging scans. The model's performance is thoroughly assessed using metrics like Mean Dice Similarity Coefficient, Sensitivity, Specificity, and Accuracy. The study evaluates the model's proficiency on 50 test images from in-house and established {BRaTS} 2020 datasets. The proposed U-net model showcases its superiority by achieving high Dice Similarity Coefficient scores, indicating a solid alignment with reference segmentations. It also demonstrates impressive sensitivity and specificity values, signifying its capacity to capture tumor regions and true negatives accurately. The results demonstrate that the proposed model effectively segments tumors on a relatively smaller dataset.},
	eventtitle = {2023 {IEEE} Biomedical Circuits and Systems Conference ({BioCAS})},
	pages = {1--5},
	booktitle = {2023 {IEEE} Biomedical Circuits and Systems Conference ({BioCAS})},
	author = {Imtiaz, Romil and Mirza, Muhammad Waqar and Siddiq, Asif and Farooq-i-Azam, Muhammad and Khan, Ishtiaq Rasool and Rahardja, Susanto},
	urldate = {2024-05-28},
	date = {2023-10},
	note = {{ISSN}: 2766-4465},
	keywords = {Adaptation models, Brain modeling, Brain tumor segmentation, Differential evolution, Image segmentation, Morphological operations, Sensitivity, Sensitivity and specificity, Solid modeling, Solids, Tumor detection},
}

@article{abd-ellah_automatic_2024,
	title = {Automatic brain-tumor diagnosis using cascaded deep convolutional neural networks with symmetric U-Net and asymmetric residual-blocks},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-59566-7},
	doi = {10.1038/s41598-024-59566-7},
	abstract = {The use of various kinds of magnetic resonance imaging ({MRI}) techniques for examining brain tissue has increased significantly in recent years, and manual investigation of each of the resulting images can be a time-consuming task. This paper presents an automatic brain-tumor diagnosis system that uses a {CNN} for detection, classification, and segmentation of glioblastomas; the latter stage seeks to segment tumors inside glioma {MRI} images. The structure of the developed multi-unit system consists of two stages. The first stage is responsible for tumor detection and classification by categorizing brain {MRI} images into normal, high-grade glioma (glioblastoma), and low-grade glioma. The uniqueness of the proposed network lies in its use of different levels of features, including local and global paths. The second stage is responsible for tumor segmentation, and skip connections and residual units are used during this step. Using 1800 images extracted from the {BraTS} 2017 dataset, the detection and classification stage was found to achieve a maximum accuracy of 99\%. The segmentation stage was then evaluated using the Dice score, specificity, and sensitivity. The results showed that the suggested deep-learning-based system ranks highest among a variety of different strategies reported in the literature.},
	pages = {9501},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Abd-Ellah, Mahmoud Khaled and Awad, Ali Ismail and Khalaf, Ashraf A. M. and Ibraheem, Amira Mofreh},
	urldate = {2024-06-02},
	date = {2024-04-25},
	langid = {english},
	keywords = {Computer science, Biomedical engineering, Design, Magnetic resonance imaging, Software, synthesis and processing},
}

@inproceedings{ding_slf-unet_2024,
	location = {Cham},
	title = {{SLf}-{UNet}: Improved {UNet} for Brain {MRI} Segmentation by Combining Spatial and Low-Frequency Domain Features},
	isbn = {978-3-031-50075-6},
	doi = {10.1007/978-3-031-50075-6_32},
	shorttitle = {{SLf}-{UNet}},
	abstract = {Deep learning-based methods have shown remarkable performance in brain tumor image segmentation. However, there is a lack of research on segmenting brain tumor lesions using frequency domain features of images. To address this gap, an improved network {SLf}-{UNet} has been proposed in this paper, which is a two-dimensional encoder-decoder architecture combining spatial and low-frequency domain features based on U-Net. The proposed model effectively learns information from spatial and frequency domains. Herein, we present a novel upsample approach by using zero padding in the high-frequency region and replacing the part of the convolution operation with a convolution block combining spatial frequency domain features. Our experimental results demonstrate that our method outperforms current mainstream approaches on {BraTS} 2019 and {BraTS} 2020 datasets. Code is available soon at https://github.com/{noseDewdrop}/{SLf}-{UNet}.},
	pages = {415--426},
	booktitle = {Advances in Computer Graphics},
	publisher = {Springer Nature Switzerland},
	author = {Ding, Hui and Lu, Jiacheng and Cai, Junwei and Zhang, Yawei and Shang, Yuanyuan},
	editor = {Sheng, Bin and Bi, Lei and Kim, Jinman and Magnenat-Thalmann, Nadia and Thalmann, Daniel},
	date = {2024},
	langid = {english},
}

  
@misc{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	number = {{arXiv}:1505.04597},
	publisher = {{arXiv}},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2024-06-08},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{zhou_unet_2018,
	title = {{UNet}++: A Nested U-Net Architecture for Medical Image Segmentation},
	url = {http://arxiv.org/abs/1807.10165},
	doi = {10.48550/arXiv.1807.10165},
	shorttitle = {{UNet}++},
	abstract = {In this paper, we present {UNet}++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated {UNet}++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose {CT} scans of chest, nuclei segmentation in the microscopy images, liver segmentation in abdominal {CT} scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate that {UNet}++ with deep supervision achieves an average {IoU} gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.},
	number = {{arXiv}:1807.10165},
	publisher = {{arXiv}},
	author = {Zhou, Zongwei and Siddiquee, Md Mahfuzur Rahman and Tajbakhsh, Nima and Liang, Jianming},
	urldate = {2024-06-08},
	date = {2018-07-18},
	eprinttype = {arxiv},
	eprint = {1807.10165 [cs, eess, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning},
}
  
@article{hastomo_classification_2024,
	title = {Classification of Brain Image Tumor using {EfficientNet} B1-B2 Deep Learning},
	volume = {27},
	doi = {10.18196/st.v27i1.19691},
	abstract = {In this study, a new neural network model ({EfficientNet} B1-B2) was sought for the detection of brain tumors in magnetic resonance imaging ({MRI}) images. The primary objective was to achieve high accuracy rates so as to classify the images. The deep learning techniques meticulously processed and increased the data augmentation as much as possible for the {EfficientNet} B1-B2 models. Our experimental results show an accuracy of 98\% in the B1 version in Table {II}. This provides a potentially optimistic view of the application of artificial intelligence technology to disease diagnosis based on medical image analysis. Nonetheless, we must remind ourselves that the dataset we used has limitations in terms of the challenges it can pose. Although the number of potential variations of actual medical images constitutes a major challenge, it is not the only one. Most medical datasets are unbalanced, contain highly variable noise, have a slow internal structure, and are often small in size. Hence, our end goal is to help stimulate not only the field of brain tumor detection and treatment but also the development of more sophisticated classification models in the health context.},
	pages = {46--54},
	journaltitle = {Semesta Teknika},
	shortjournal = {Semesta Teknika},
	author = {Hastomo, Widi and Satyo, Adhitio and Sestri, Ellya and Terisia, Vany and Yusuf, Diana and Arman, Shevty and Arif, Dodi},
	date = {2024-05-02},
}


@article{zhou2019unetplusplus,
  title={UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation},
  author={Zhou, Zongwei and Siddiquee, Md Mahfuzur Rahman and Tajbakhsh, Nima and Liang, Jianming},
  journal={IEEE Transactions on Medical Imaging},
  year={2019},
  publisher={IEEE}
}

@incollection{zhou2018unetplusplus,
  title={Unet++: A Nested U-Net Architecture for Medical Image Segmentation},
  author={Zhou, Zongwei and Siddiquee, Md Mahfuzur Rahman and Tajbakhsh, Nima and Liang, Jianming},
  booktitle={Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
  pages={3--11},
  year={2018},
  publisher={Springer}
}

@phdthesis{zhou2021towards,
  title={Towards Annotation-Efficient Deep Learning for Computer-Aided Diagnosis},
  author={Zhou, Zongwei},
  year={2021},
  school={Arizona State University}
}

@misc{Yakubovskiy_2019,
  author = {Pavel Iakubovskii},
  title = {Segmentation Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/qubvel/segmentation_models}}
}
