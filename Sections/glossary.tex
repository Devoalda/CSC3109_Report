\newacronym{cnn}{CNN}{Convolution Neural Network}
\newacronym{mlp}{MLP}{Multilayer Perceptron}
\newacronym{vit}{ViT}{Vision Transformer}

\newglossaryentry{Convolutional Neural Network}
{
    name={Convolutional Neural Network (CNN)},
    description={A type of neural network particularly effective for processing grid-like data, such as images, by applying convolutional operations to extract features}
}

\newglossaryentry{Multilayer Perceptron}
{
    name={Multilayer Perceptron (MLP)},
    description={A class of feedforward artificial neural network consisting of multiple layers of nodes, each layer fully connected to the next, commonly used for classification and regression tasks}
}


\newglossaryentry{Vision Transformer}
{
name={Vision Transformer (ViT)},
description={A type of neural network model that adapts the transformer architecture, originally designed for natural language processing, to image recognition tasks. ViT divides an image into fixed-size patches, linearly embeds each of them, adds positional encodings, and processes the sequence of embeddings through multiple transformer layers. This approach allows ViT to capture global interactions between patches, making it effective for large-scale image classification tasks.}
}
