\section{Existing Approaches to Brain MRI Classification Using Deep Learning}\label{s:lit_review}

The integration of deep learning into the medical field has revolutionized diagnostic methodologies, particularly in the classification of brain MRI images. As brain tumors present diverse morphological characteristics that are detectable through MRI, the precision of image analysis can significantly influence diagnostic and treatment outcomes. This literature review examines current deep learning approaches that enhance the accuracy and efficiency of brain tumor diagnoses from MRI scans, focusing on the evolution of model architectures, data preprocessing innovations, and the strategic application of transfer learning.

\subsection{Data preprocessing techniques}

Data preprocessing is a crucial step in enhancing the accuracy of brain MRI classification models. Techniques such as data augmentation \cite{10183465} and cropping along contours of brain MRIs play significant roles in improving model training and performance. Data augmentation involves creating modified versions of the original images through transformations such as rotation, scaling, and flipping. This process helps in increasing the diversity of the training dataset, which in turn aids in preventing overfitting and improves the generalization capabilities of the models \cite{Paul2017Deep}.

Cropping along the contours of the brain in MRI images helps in focusing the model’s attention on the most relevant areas, thereby reducing noise and improving classification accuracy. By eliminating irrelevant parts of the image, this technique ensures that the model learns more effectively from the essential features of the brain structure \cite{Asif2022Improving}.

In addition, advanced preprocessing methods like Generative Adversarial Networks (GANs) for augmented data generation have shown to significantly improve the robustness and accuracy of brain MRI classification models by generating high-quality synthetic data to augment the small training set \cite{Fahimi2020Generative}.

These preprocessing techniques collectively enhance the quality and quantity of the training data, leading to more accurate and reliable brain MRI classification models.

\subsection{Convolutional Neural Networks (CNNs) and Variants}

Convolutional Neural Networks (CNNs) have been extensively used for brain MRI classification. A notable approach is the use of ResNet-18 architecture for differentiating MRI sequence types, achieving an impressive accuracy of 97.9\% on test sets. This model demonstrates the capability of CNNs in handling complex MRI data efficiently\cite{doi:10.1148/ryai.230095}.

\subsubsection{U-Net and Variants}

U-Net and its numerous variants have established themselves as fundamental architectures in the realm of brain MRI segmentation, owing to their exceptional ability to effectively capture spatial information. The U-Net architecture, initially designed for biomedical image segmentation, has been widely applied to brain tumor segmentation in MRI images, achieving remarkable accuracy and robustness in detecting tumors \cite{imtiaz_brain_2023, abd-ellah_automatic_2024, ding_slf-unet_2024}.

To enhance the performance of U-Net in medical image analysis, several adaptations have been proposed. Abd-Ellah et al. \cite{abd-ellah_automatic_2024} introduced the Two Parallel Cascaded U‑Nets with an Asymmetric Residual (TPCUAR‑Net) architecture. This innovative two-stage detection and segmentation model demonstrated high accuracy in brain tumor tasks, highlighting the significant potential of U-Net variants.

Similarly, Imtiaz et al. \cite{imtiaz_brain_2023} developed a modified U-Net architecture tailored for pixel-level segmentation using a relatively small dataset of 322 brain tumor MRI images. Their model achieved impressive accuracy and robustness, further validating the efficacy of U-Net in medical image analysis.

Ding et al. \cite{ding_slf-unet_2024} proposed the SLF-UNet architecture, which integrates U-Net with a spatial attention mechanism to enhance segmentation precision. The SLF-UNet model achieved significant improvements in tumor segmentation accuracy, highlighting the advantages of incorporating attention mechanisms into the U-Net framework.

Zhou et al. \cite{zhou2018unetplusplus} presented U-Net++, a novel architecture that incorporates dense skip connections and deep supervision to bolster segmentation performance. The U-Net++ model demonstrated superior performance compared to traditional U-Net architectures, showcasing the potential of advanced U-Net variants in medical image segmentation.

Eff-U-Net, introduced by Baheti et al. \cite{baheti_eff-unet_2020}, combines the U-Net architecture with EfficientNets for the downsampling path. This hybrid model achieved state-of-the-art performance in various medical segmentation tasks, such as Pneumonia Detection \cite{yu_pneumonia_2021} and Brain Tumor Segmentation \cite{lin_brain_2024}, highlighting the efficacy of integrating EfficientNets into the U-Net framework.

These studies collectively illustrate the versatility and effectiveness of U-Net and its variants in brain tumor segmentation, solidifying their role as invaluable tools in the field of medical image analysis.

\subsection{Transfer Learning in Brain MRI Classification}

Transfer learning has emerged as a powerful technique for enhancing the performance of deep learning models, particularly in scenarios with limited labeled data. This method involves leveraging pre-trained models on large-scale datasets and adapting them to specific tasks such as brain MRI classification. The underlying principle is that features learned from a broad dataset can be transferred to a new task, reducing the need for extensive labeled data and computational resources.

Several transfer learning architectures, including InceptionV3, VGG19, ResNet-50, and MobileNet, have been applied to brain MRI classification for various applications, such as brain tumor diagnosis. For instance, MobileNet has demonstrated exceptional performance, achieving an accuracy of 99.60\% in brain tumor classification tasks, underscoring the potential of transfer learning in achieving high accuracy with relatively small datasets  \cite{Islam_Barua_Rahman_Ahammed_Akter_Uddin_2023}. This success can be attributed to the model's ability to effectively transfer features learned from natural image datasets to medical imaging tasks.

In the context of whole-brain functional MRI (fMRI) data, transfer learning has been employed to tackle the challenges posed by small sample sizes and high dimensionality. Studies have shown that models utilizing transfer learning exhibit improved performance compared to those trained from scratch. This improvement is evident in the enhanced ability to capture relevant patterns in complex, high-dimensional fMRI data, thus facilitating more accurate brain function analysis \cite{10.1007/978-3-030-32695-1_7}.

Moreover, transfer learning has proven beneficial in brain tumor detection. For example, a study applied a pre-trained deep learning model, initially trained on a large dataset of natural images, to the task of brain MRI classification. The fine-tuned model achieved comparable performance with smaller, domain-specific datasets, demonstrating that transfer learning can effectively bridge the gap between different domains and reduce the dependency on large medical imaging datasets \cite{10125766}.

\subsubsection{ResNet-50}
Among these architectures, ResNet-50 has gained significant attention due to its unique ability to mitigate the vanishing gradient problem through the use of residual learning. ResNet-50, a 50-layer deep convolutional neural network, utilizes shortcut connections that allow the network to learn residual functions with reference to the layer inputs, which substantially improves the convergence rate of the network \cite{He_Zhang_Ren_Sun_2015}.

In the domain of brain MRI classification, ResNet-50 has been extensively employed for its robustness and ability to handle complex image data. Its deep architecture is particularly effective in extracting intricate features from MRI scans, which is crucial for distinguishing between different types of brain pathologies. For example, in brain tumor classification tasks, ResNet-50 has been adapted to differentiate between gliomas, meningiomas, and pituitary tumors with high accuracy \cite{Cheng_Huang_Cao_Yang_Yang_Yun_Wang_Feng_2015}. The model's depth and residual connections enable it to capture subtle differences in brain tissue characteristics that are critical for accurate diagnosis.

Research has demonstrated that ResNet-50, when fine-tuned on brain MRI datasets, can significantly outperform traditional machine learning techniques. For instance, in a study focusing on brain tumor classification, ResNet-50 coupled with the convolutional block attention module (CBAM) achieved an accuracy rate of 99.43\%, highlighting its effectiveness in medical image classification \cite{Oladimeji_Ibitoye_2023}. The pre-trained nature of ResNet-50 allows it to leverage feature representations from extensive datasets like ImageNet, which can be adapted to the specific features found in brain MRI images, thereby enhancing the model's generalization ability and diagnostic accuracy.

\subsubsection{Xception}
Xception, a convolutional neural network that is 71 layers deep with a modified depth-wise separable convolution, proposed by Chollet Francis, and is build upon the foundations of Inception model architecture. Xception slightly outperformed InceptionV3 on the ImageNet dataset and it has the same number of model parameters as Inception \cite{Francois_Chollet}. The Xception has replaced the inception module with a modified depth-wise separable convolution on the Inception model.

To leverage deep learning architecture for this classification task, a study showed the use of the Xception model, highlighting its efficient depth-wise separable convolutions, which enhance performance and adaptability. The model's application in medical imaging particularly for multi-class classification tasks, demonstrates its high accuracy and efficiently \cite{li2024leveraging}.

An IEEE research has provided results in supporting the efficacy of utilizing Xception transfer learning model in the crucial medical imaging domain to detect brain tumour diseases. The model's performance is essential, as it achieves a high accuracy of 96\% through the training process of 40 epochs. This outcome is achieved by implementing a small batch size number of eight and various optimizer \cite{10511504}. In another recent IEEE study further explored the application of the Xception model for brain tumour classification. By leveraging advanced data augmentation techniques and transfer learning, the researchers achieved remarkable accuracy rates, demonstrating the model's efficiency in distinguishing between different types of brain tumours. This study highlights the continued advancements and applicability of the Xception model in enhancing medical image analysis and classification accuracy \cite{10331713}.

To sum it up, the Xception model excels in medical imaging tasks, particularly brain tumour classification tasks, due to its innovative depth-wise separable convolutions which enhance computational efficiency and accuracy. Its proven high performance underscore its value as a tool in complex image classification tasks.

\subsubsection{DenseNet121}
DenseNet121, a variation of the Densely Connected Convolutional Networks (DenseNet)\cite{DenseNet121_2017}, has garnered significant attention in the field of deep learning due to its innovative architecture and superior performance in image classification tasks. DenseNet121 is characterized by its dense connectivity pattern, where each layer receives input from all preceding layers and passes its own feature maps to all subsequent layers. This design promotes feature reuse, mitigates the vanishing gradient problem, and improves network efficiency by reducing the number of parameters compared to traditional convolutional networks .

The application of DenseNet121 spans various domains, with notable success in medical imaging. For instance, studies have demonstrated its efficacy in detecting diseases from chest X-rays\cite{chest_X-rays_2017} and classifying skin cancer\cite{skin_cancer_2017} from dermatological images. The model's ability to leverage features from multiple layers allows it to capture intricate patterns and textures in medical images, leading to higher diagnostic accuracy. Comparative studies have shown that DenseNet121 outperforms other convolutional neural networks (CNNs) like ResNet and VGGNet in these tasks, highlighting its robustness and precision .

Despite its advantages, DenseNet121 faces challenges, particularly in computational cost and memory usage due to its dense connections. Researchers have proposed various modifications to address these issues, such as pruning techniques\cite{Pruning_2019} and hybrid models that combine DenseNet121 with other architectures to enhance efficiency without compromising accuracy. Future research is directed towards optimizing DenseNet121\cite{Optimizing_2023} for deployment in resource-constrained environments and exploring its potential in other areas such as natural language processing and autonomous driving.

\subsubsection{Vision Transformers}

Transformers, first proposed by Vaswani et al. for natural language processing (NLP) tasks, are a typical attention-based deep learning model \cite{NIPS2017_3f5ee243}. Vision Transformers (ViTs) have emerged as a powerful tool in medical imaging, particularly for classifying brain MRI images to detect tumors. Inspired by the success of transformers in natural language processing (NLP), where they have replaced RNNs and CNNs due to their ability to model long-range dependencies between tokens, ViTs adapt this architecture for image analysis. Initially proposed by Dosovitskiy et al., ViTs divide input images into non-overlapping patches and model the global relations between these patches using multiple standard transformer layers \cite{dosovitskiy2021image}. This unique approach allows for a comprehensive evaluation of spatial relationships and features within brain scans.

ViTs utilize self-attention mechanisms to analyze different image segments simultaneously, enhancing the detection of subtle variances and complex patterns indicative of tumors. This method offers significant advantages in accuracy and efficiency over traditional CNN and RNN-based methods, despite higher computational costs. By focusing on critical image areas, ViTs improve the precision of tumor detection and classification, making them invaluable in diagnostic radiology.

Several studies have highlighted the efficacy of ViTs in medical imaging. Research conducted by Tummala et al. \cite{Tummala2022} reveals that ViT consistently achieve high classification accuracies, surpassing 97\% in both validation and testing phases. This impressive accuracy persists across a range of hyperparameter configurations, including optimizer, learning rate (lr), number of epochs (ne), and minibatch size (mbs), underscoring the robustness of ViT models in various operational conditions.

Additionally, a study by Asiri et al. assessed five pre-trained ViT models, namely R50-ViT-l16, ViT-l16, ViT-l32, ViT-b16, and ViT-b32, for brain tumor classification. The results revealed that the ViT-b32 model achieved the highest accuracy of 98.24\%, surpassing existing methods \cite{Asiri2023Advancing}. 

Furthermore, Diker's analysis of transfer learning models indicated that pre-trained ViT models surpassed CNN models such as VGG-16 and ResNet-50, which achieved accuracies of 96\% and 88\% respectively \cite{Diker2021A}.

Overall, the application of Vision Transformers in the classification of brain MRI images for tumor detection highlights their advanced capabilities and potential to enhance diagnostic accuracy in medical imaging.


\subsection{Conclusion}

% In conclusion, deep learning has significantly advanced the field of brain MRI classification, offering robust, accurate, and efficient solutions for diagnosing and monitoring brain tumors. The continuous evolution of CNN architectures, transfer learning techniques, optimization strategies, and preprocessing methods promises further enhancements in the accuracy and reliability of these models, ultimately contributing to improved patient outcomes and reduced diagnostic times. These advancements not only highlight the transformative potential of deep learning in medical imaging but also underscore the importance of ongoing research and development. By continuing to refine and innovate upon these techniques, the medical community can look forward to even more effective and efficient diagnostic tools, paving the way for better patient care and outcomes.

Deep learning technologies, particularly through models like ViT and CNNs, have revolutionized the field of brain MRI classification. These advances provide robust, accurate, and efficient diagnostic tools for identifying and monitoring brain tumors. As technology progresses, the ongoing development of CNN architectures, transfer learning techniques, optimization strategies, and preprocessing methods are expected to further enhance the accuracy and reliability of these models. This continual evolution not only underlines the transformative impact of deep learning on medical imaging but also emphasizes the critical importance of sustained research and development in this area. By pushing the boundaries of what's possible with these technologies, the medical community can anticipate more effective and streamlined diagnostic processes, leading to improved patient care and outcomes. This ongoing innovation is key to harnessing the full potential of deep learning in enhancing healthcare delivery.
